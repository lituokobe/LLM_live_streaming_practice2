{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f57b86f-f932-41ff-91a6-1efbb14ceef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total report count: 18\n",
      "Report count after filtering by community level 2: 18\n",
      "                                 id  human_readable_id  community  level  \\\n",
      "0  5e570ebe27604f85bed68d00cd6c7739                  8          8      1   \n",
      "1  035400b00ec84e59b619fc0b416d5558                  9          9      1   \n",
      "2  ca1cb9b75bfe4e01b6fcbdb2b94609f8                 10         10      1   \n",
      "3  ec51fe40ef474431ba1235ce4c0e43a6                 11         11      1   \n",
      "4  e7ac2112d5054a8ebbdc011197fdbdcf                 12         12      1   \n",
      "\n",
      "   parent children                                              title  \\\n",
      "0       0       []  Yongle Emperor's Architectural and Cultural Le...   \n",
      "1       0       []  Historical and Political Influence of Kangxi a...   \n",
      "2       1       []  Key Figures and Events of the Ming Dynasty and...   \n",
      "3       1       []  Historical and Political Significance of Nanji...   \n",
      "4       1       []                   Yongle Period and Emperor Zhu Di   \n",
      "\n",
      "                                             summary  \\\n",
      "0  This community centers around Yongle Emperor, ...   \n",
      "1  This community centers around Kangxi, a promin...   \n",
      "2  This community encompasses significant histori...   \n",
      "3  This community centers around the city of Nanj...   \n",
      "4  The community centers around the Yongle period...   \n",
      "\n",
      "                                        full_content  rank  \\\n",
      "0  # Yongle Emperor's Architectural and Cultural ...   7.5   \n",
      "1  # Historical and Political Influence of Kangxi...   7.5   \n",
      "2  # Key Figures and Events of the Ming Dynasty a...   7.5   \n",
      "3  # Historical and Political Significance of Nan...   6.0   \n",
      "4  # Yongle Period and Emperor Zhu Di\\n\\nThe comm...   7.0   \n",
      "\n",
      "                                  rating_explanation  \\\n",
      "0  The impact severity rating is relatively high ...   \n",
      "1  The impact severity rating is relatively high ...   \n",
      "2  The impact severity rating is relatively high ...   \n",
      "3  The impact severity rating is moderate, given ...   \n",
      "4  The impact severity rating is moderate to high...   \n",
      "\n",
      "                                            findings  \\\n",
      "0  [{'explanation': 'Yongle Emperor is the key en...   \n",
      "1  [{'explanation': 'Kangxi was a prominent emper...   \n",
      "2  [{'explanation': 'Nurhachi was a prominent Jur...   \n",
      "3  [{'explanation': 'Nanjing is a major city in C...   \n",
      "4  [{'explanation': 'The Yongle period (1402-1424...   \n",
      "\n",
      "                                   full_content_json      period  size  \n",
      "0  {\\n    \"title\": \"Yongle Emperor's Architectura...  2025-09-25     7  \n",
      "1  {\\n    \"title\": \"Historical and Political Infl...  2025-09-25     4  \n",
      "2  {\\n    \"title\": \"Key Figures and Events of the...  2025-09-25     5  \n",
      "3  {\\n    \"title\": \"Historical and Political Sign...  2025-09-25     2  \n",
      "4  {\\n    \"title\": \"Yongle Period and Emperor Zhu...  2025-09-25     2  \n",
      "                                     id  human_readable_id         title  \\\n",
      "0  d66064b5-4b41-4535-aed5-93809defd883                  0  QING DYNASTY   \n",
      "1  0bb2b7c2-70ae-47a7-ae08-a4e81c9aa371                  1        DAQING   \n",
      "2  3f00d87c-0f69-4dcc-9908-01faf56c7a48                  2       EMPEROR   \n",
      "3  4ee67239-874f-4818-8329-c7fbd76486c1                  3   SHUNTIAN FU   \n",
      "4  293efdc3-3c3e-4161-8f30-2790e6fb4cb4                  4      SHENYANG   \n",
      "\n",
      "           type                                        description  \\\n",
      "0  ORGANIZATION  The Qing Dynasty was the last imperial dynasty...   \n",
      "1  ORGANIZATION  The official name of the Qing Dynasty, meaning...   \n",
      "2        PERSON  The ruler of the Qing Dynasty, including emper...   \n",
      "3           GEO  The capital of the Qing Dynasty from 1644 to 1...   \n",
      "4           GEO  Shenyang, historically known as Mukden or Shen...   \n",
      "\n",
      "                                       text_unit_ids  frequency  degree    x  \\\n",
      "0  [f444d24aabd36cfadd175743cb71cd0c2c548de996c92...          8      56  0.0   \n",
      "1  [f444d24aabd36cfadd175743cb71cd0c2c548de996c92...          1       0  NaN   \n",
      "2  [f444d24aabd36cfadd175743cb71cd0c2c548de996c92...          1       0  NaN   \n",
      "3  [f444d24aabd36cfadd175743cb71cd0c2c548de996c92...          1       1  0.0   \n",
      "4  [f444d24aabd36cfadd175743cb71cd0c2c548de996c92...          2       1  0.0   \n",
      "\n",
      "     y  \n",
      "0  0.0  \n",
      "1  NaN  \n",
      "2  NaN  \n",
      "3  0.0  \n",
      "4  0.0  \n",
      "                                     id  human_readable_id  community  level  \\\n",
      "0  9dd7c98c-9453-426d-9a1b-92ad19da8dcd                  0          0      0   \n",
      "1  a16c817e-3894-4eac-a222-601d3421436e                  1          1      0   \n",
      "2  7a16526f-3436-4ff0-af10-872ec8210d14                  2          2      0   \n",
      "3  becd5ece-00c3-4c92-9fbe-13b8ca8d12a2                  3          3      0   \n",
      "4  0fd07928-e8c4-4cd5-b406-73a30e878841                  4          4      0   \n",
      "\n",
      "   parent              children        title  \\\n",
      "0      -1                [8, 9]  Community 0   \n",
      "1      -1  [10, 11, 12, 13, 14]  Community 1   \n",
      "2      -1                    []  Community 2   \n",
      "3      -1                    []  Community 3   \n",
      "4      -1                    []  Community 4   \n",
      "\n",
      "                                          entity_ids  \\\n",
      "0  [2929e1b9-622e-4117-8a22-dfc41df3d20b, d59be02...   \n",
      "1  [11194a53-a8e0-48e0-ad7a-4ee27e46368d, 44c24b2...   \n",
      "2  [5ea96ee8-a595-4d86-aa1f-3f550581312b, 5eba04f...   \n",
      "3  [2d57299b-301c-40ea-a26e-834d506c45bc, d4739c7...   \n",
      "4  [2206941a-b5e8-4310-8df9-087692ab9135, a82cc28...   \n",
      "\n",
      "                                    relationship_ids  \\\n",
      "0  [08818d2e-887e-4c3b-8aca-8efa1f2a539f, 1357c62...   \n",
      "1  [0296a25b-fc15-4f8c-8194-ffcaf3a75f30, 559550e...   \n",
      "2  [07aa38ca-de69-447f-8e36-35c150133ac9, 102d0b2...   \n",
      "3             [ec8fccbe-8f17-4e6c-9b71-6d0fe03afaf8]   \n",
      "4             [61a44e48-c011-4734-a5bc-fc5f2b400884]   \n",
      "\n",
      "                                       text_unit_ids      period  size  \n",
      "0  [4e4fc6f3fcaa938fee06632b663e0f8c77ba366cd5da0...  2025-09-25    11  \n",
      "1  [3616dc02a87f00118d6abf7ca9a033856e08e97bfac28...  2025-09-25    15  \n",
      "2  [1bf1cb2fa99fa64d96c20e16258c8bf4a4c7c91ea62b4...  2025-09-25    21  \n",
      "3  [4d5a127492c6aaa457e15aaf02b6686dd2aa1dfc2b471...  2025-09-25     2  \n",
      "4  [c8392a2b6a3171dfe145f538097661df0ee122c2b0888...  2025-09-25     2  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "GlobalCommunityContext.__init__() got an unexpected keyword argument 'token_encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(entity_df.head())\n\u001b[32m     82\u001b[39m \u001b[38;5;28mprint\u001b[39m(community_df.head())\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m context_builder = \u001b[43mGlobalCommunityContext\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommunity_reports\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreports\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommunities\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommunities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mentities\u001b[49m\u001b[43m=\u001b[49m\u001b[43mentities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default to None if you don't want to use community weights for ranking\u001b[39;49;00m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_encoder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_encoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m context_builder_params = {\n\u001b[32m     94\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33muse_community_summary\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# False means using full community reports. True means using community short summaries.\u001b[39;00m\n\u001b[32m     95\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mshuffle_data\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcontext_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mReports\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    104\u001b[39m }\n\u001b[32m    106\u001b[39m map_llm_params = {\n\u001b[32m    107\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1000\u001b[39m,\n\u001b[32m    108\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.0\u001b[39m,\n\u001b[32m    109\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mjson_object\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m    110\u001b[39m }\n",
      "\u001b[31mTypeError\u001b[39m: GlobalCommunityContext.__init__() got an unexpected keyword argument 'token_encoder'"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "from graphrag.config.enums import ModelType\n",
    "from graphrag.config.models.language_model_config import LanguageModelConfig\n",
    "from graphrag.language_model.manager import ModelManager\n",
    "from graphrag.query.indexer_adapters import (\n",
    "    read_indexer_communities,\n",
    "    read_indexer_entities,\n",
    "    read_indexer_reports,\n",
    ")\n",
    "from graphrag.query.structured_search.global_search.community_context import (\n",
    "    GlobalCommunityContext,\n",
    ")\n",
    "from graphrag.query.structured_search.global_search.search import GlobalSearch\n",
    "import logging\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"./test_graphrag/.env\")\n",
    "api_key = os.getenv(\"GRAPHRAG_API_KEY\")\n",
    "\n",
    "# 配置日志输出到控制台和文件\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # 设置为最低级别以捕获所有信息\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"graphrag_debug.log\"),  # 输出到文件\n",
    "        logging.StreamHandler()  # 输出到控制台\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 确保 GraphRAG 相关模块启用调试\n",
    "logger = logging.getLogger(\"graphrag\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "llm_model = 'gpt-4o-mini'\n",
    "\n",
    "# 创建了大模型连接对象\n",
    "config = LanguageModelConfig(\n",
    "    api_key=api_key,\n",
    "    api_base='https://api.openai.com/v1',\n",
    "    type=ModelType.OpenAIChat,\n",
    "    model=llm_model,\n",
    "    max_retries=3,\n",
    ")\n",
    "model = ModelManager().get_or_create_chat_model(\n",
    "    name=\"global_search\",\n",
    "    model_type=ModelType.OpenAIChat,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "token_encoder = tiktoken.encoding_for_model(llm_model)\n",
    "\n",
    "# parquet files generated from indexing pipeline\n",
    "INPUT_DIR = \"./test_graphrag/output\"\n",
    "COMMUNITY_TABLE = \"communities\"\n",
    "COMMUNITY_REPORT_TABLE = \"community_reports\"\n",
    "ENTITY_TABLE = \"entities\"\n",
    "\n",
    "# community level in the Leiden community hierarchy from which we will load the community reports\n",
    "# higher value means we use reports from more fine-grained communities (at the cost of higher computation cost)\n",
    "COMMUNITY_LEVEL = 2\n",
    "\n",
    "community_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_TABLE}.parquet\")\n",
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "\n",
    "communities = read_indexer_communities(community_df, report_df)\n",
    "reports = read_indexer_reports(report_df, community_df, COMMUNITY_LEVEL)\n",
    "entities = read_indexer_entities(entity_df, community_df, COMMUNITY_LEVEL)\n",
    "\n",
    "print(f\"Total report count: {len(report_df)}\")\n",
    "print(\n",
    "    f\"Report count after filtering by community level {COMMUNITY_LEVEL}: {len(reports)}\"\n",
    ")\n",
    "\n",
    "print(report_df.head())\n",
    "print(entity_df.head())\n",
    "print(community_df.head())\n",
    "\n",
    "\n",
    "\n",
    "context_builder = GlobalCommunityContext(\n",
    "    community_reports=reports,\n",
    "    communities=communities,\n",
    "    entities=entities,  # default to None if you don't want to use community weights for ranking\n",
    "    token_encoder=token_encoder,\n",
    ")\n",
    "\n",
    "context_builder_params = {\n",
    "    \"use_community_summary\": False,  # False means using full community reports. True means using community short summaries.\n",
    "    \"shuffle_data\": True,\n",
    "    \"include_community_rank\": True,\n",
    "    \"min_community_rank\": 0,\n",
    "    \"community_rank_name\": \"rank\",\n",
    "    \"include_community_weight\": True,\n",
    "    \"community_weight_name\": \"occurrence weight\",\n",
    "    \"normalize_community_weight\": True,\n",
    "    \"max_tokens\": 12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "    \"context_name\": \"Reports\",\n",
    "}\n",
    "\n",
    "map_llm_params = {\n",
    "    \"max_tokens\": 1000,\n",
    "    \"temperature\": 0.0,\n",
    "    \"response_format\": {\"type\": \"json_object\"},\n",
    "}\n",
    "\n",
    "reduce_llm_params = {\n",
    "    \"max_tokens\": 2000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 1000-1500)\n",
    "    \"temperature\": 0.0,\n",
    "}\n",
    "\n",
    "search_engine = GlobalSearch(\n",
    "    model=model,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    max_data_tokens=12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "    map_llm_params=map_llm_params,\n",
    "    reduce_llm_params=reduce_llm_params,\n",
    "    allow_general_knowledge=False,  # set this to True will add instruction to encourage the LLM to incorporate general knowledge in the response, which may increase hallucinations, but could be useful in some use cases.\n",
    "    json_mode=True,  # set this to False if your LLM model does not support JSON mode.\n",
    "    context_builder_params=context_builder_params,\n",
    "    concurrent_coroutines=32,\n",
    "    response_type=\"multiple paragraphs\",  # free form text describing the response type and format, can be anything, e.g. prioritized list, single paragraph, multiple paragraphs, multiple-page report\n",
    ")\n",
    "\n",
    "async def run_search():\n",
    "    result = await search_engine.search(\"清朝有哪些名臣？\")\n",
    "\n",
    "    print(result.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9528d8c2-1579-4039-b0ce-f2d355ed5fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
