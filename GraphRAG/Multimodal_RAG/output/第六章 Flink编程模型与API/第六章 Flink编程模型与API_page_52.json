[{"bbox": [135, 101, 608, 148], "category": "Title", "text": "## Java代码实现-只写出value"}, {"bbox": [123, 198, 1607, 1856], "category": "Text", "text": "```java\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n/*\n * Socket中输入数据如下:\n * hello,flink\n * hello,spark\n * hello,hadoop\n * hello,java\n */\nuloaStreamSource <String> ds1 = env.socketTextStream(\"node5\", 9999);\n\n//统计wordcount\nSingleOutputStreamOperator <String> result = ds1JoinMap((FlatMapFunction <String, String>) (s, collector) -\n    String[] arr = s.split(\",\");\n    for (String word : arr) {\n        collector.collect(word);\n    }\n).returns(Types.STRING)\n.map(one -> Tuple2.of(one, 1)).returns(Types.TUPLE(Types.STRING, Types.IN T))\n.keyBy.tp -> tp.f0)\n.sum(1)\n.map(one -> one.f0 + \"-\" + one.f1).returns(Types.STRING);\n\n//准备Flink KafkaSink对象\nKafkaSink <String> kafkaSink = KafkaSink . <String> builder()\n    .setBootstrapServers(\"node1:9092, node2:9092, node3:9092\")\n    //设置事务超时时间,最大不超过kafka broker的事务最大超时时间限制: max.transaction.timeout.ms\n    .setProperty(\"transaction.timeout.ms\", 15 * 60 * 1000L + \"\")\n    .setRecord(KafkaRecordSchema . builder()\n        .setTopic(\"flink-topic\")\n        . sou\n        .build()\n    )\n    .setDeliveryGuarantee(DeliveryGuarantee .EXACTLY_ONCE)\n    .build();\n\n//将结果写出到Kafka\nresult.sinkTo(kafkaSink);\n\nenv.execute();\n```"}, {"bbox": [135, 1905, 716, 1953], "category": "Title", "text": "## Java代码实现-写出Key、Value数据"}, {"bbox": [123, 2002, 1408, 2082], "category": "Text", "text": "```java\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n/*\n```"}]