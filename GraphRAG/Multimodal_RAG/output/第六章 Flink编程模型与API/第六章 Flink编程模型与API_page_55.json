[{"bbox": [115, 96, 1188, 1212], "category": "Text", "text": "```kotlin\nval kafkaSink: KafkaSink[(String, Int)] = KafkaSink builder[(String, Int)]()\n.setBootstrapServers(\"node1:9092,node2:9092,node3:9092\")\n PROPERTY(\"transaction.timeout.ms\", 15 * 60 * 1000L + \"\")\n.setRecord(\n    KafkaRecord serializationSchema builder()\n    .setTopic(\"flink-topic-2\")\n    .setKey serializationSchema(new MyKey serializationSchema())\n    . value serializationSchema(new MyValue serializationSchema())\n    .build()\n).setDeliveryGuarantee(DeliveryGuarantee.EXACTLY ONCE)\n.build()\n\nresult.sinkTo(kafkaSink)\n\nenv.execute()\n}\n}\n\nclass MyKey serializationSchema() extends SerializationSchema[(String,Int)]{\n    override def serialize(t: (String, Int)): Array[Byte] = t_1_bytes\n}\n\nclass MyValue serializationSchema() extends SerializationSchema[(String,Int)]{\n    override def serialize(t: (String, Int)): Array[Byte] = t_2.toStringurgi\n}\n```"}, {"bbox": [115, 1253, 821, 1304], "category": "Title", "text": "### 3) 向Socket中输入以下数据，查看Kafka中结果"}, {"bbox": [124, 1347, 314, 1521], "category": "Text", "text": "```\nhello,flink\nhello,spark\nhello,hadoop\nhello,java\n```"}, {"bbox": [115, 1586, 447, 1641], "category": "Section-header", "text": "## 6.6.4 RedisSink"}, {"bbox": [115, 1676, 1563, 1774], "category": "Text", "text": "Flink官方没有直接提供RedisSink连接器而是通过Apache Bahir项目提供的一个附加的流式连接器: Redis Connector,该连接器用于Apache Flink和Redis之间的数据交互。"}, {"bbox": [115, 1810, 1563, 1956], "category": "Text", "text": "注: Apache Bahir是一个扩展项目,旨在为Apache Flink提供额外的流式连接器。这些连接器可以扩展Flink的功能,使其能够与不同的数据源和数据接收器进行无缝集成,其中之一就是Flink RedisConnector。"}]