[{"bbox": [128, 102, 724, 440], "category": "Text", "text": "```xml\n</dependency>\n\n <!--读取HDFS 数据需要的依赖 -->\n<dependency>\n<groupId>org.apache hadoop</groupId>\n<artifactId>hadoop-client</ artifactId>\n<version> ${hadoop.version}</version>\n</dependency>\n```"}, {"bbox": [134, 491, 408, 535], "category": "List-item", "text": "* **Java代码如下：**"}, {"bbox": [126, 586, 1602, 1390], "category": "Text", "text": "```java\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n/**\n * Flink1.14版本之前读取文件写法\n */\n// DataStreamSource<String> dataStream = env.readTextFile(\"hdfs://mycluster/flinkdata/data.txt\");\n// dataStream.print();\n\n/**\n * Flink 读取文件最新写法\n */\nFileSource<String> fileSource = FileSource.forRecordStreamFormat(\n    new TextLineInputFormat(),\n    new Path(\"hdfs://mycluster/flinkdata/data.txt\")).build();\n\nibiStreamSource = env.fromSource(fileSource, WatermarkStrategy.noWatermark\n\ndataStream.print();\n\nenv.execute();\n```"}, {"bbox": [134, 1443, 408, 1486], "category": "List-item", "text": "* **Scala代码如下：**"}, {"bbox": [126, 1540, 1600, 2046], "category": "Text", "text": "```scala\nval env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment\n\nimport org.apache flink api Play\n\nval fileSource: FileSource [String] = FileSource.forRecordStreamFormat(\n    new TextLineInputFormat(),\n    new Path(\"hdfs://mycluster/flinkdata/data.txt\")\n).build()\n\nval dataStream: DataStream [String] = env.fromSource(fileSource, WatermarkStrategy.noWatermarks(), \"file-s\")\n\ndataStream.print()\n```"}]