[{"bbox": [126, 103, 320, 311], "category": "Text", "text": "```groovy\n}\n});\n\nresult.print();\nenv.execute();\n```"}, {"bbox": [135, 364, 402, 406], "category": "Title", "text": "## Scala代码实现"}, {"bbox": [126, 460, 1436, 1178], "category": "Text", "text": "```groovy\nval env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment\n//导入隐式转换\nimport org.apacheフlinkKAstreaming.apia scaledot_\nval ds1: DataStream[(String, Int)] = env.socketTextStream(\"node5\", 9999)\nval ds2: DataStream[(String, Int)] = ds1.map(one => {\n  val arr: Array[(String)] = one.split(\",\")\n  (arr(0), arr(1). Int)\n})\nval result: DataStream[(String, Int)] = ds2itecton custom (new Partitionerform String) {\n  override def partition(key: String, numPartitions: Int): Int = {\n    keyeft Code % numPartitions\n  }\n}, _ _ 1)\nresult.print()\nenv.execute()\n```"}, {"bbox": [114, 1232, 1030, 1274], "category": "Text", "text": "以上Java或者Scala代码执行时可以在Socket中输入如下数据："}, {"bbox": [126, 1330, 172, 1533], "category": "Text", "text": "```\na,1\nb,2\na,3\nb,4\nc,5\n```"}, {"bbox": [114, 1605, 655, 1669], "category": "Title", "text": "## 6.8 Side Output侧输出"}, {"bbox": [114, 1704, 1586, 1996], "category": "Text", "text": "在Flink处理数据流时,常常会面临这样的情况:需要对一个数据源进行处理,该数据源包含不同类型的数据,我们需要将其分割处理。使用filter算子对数据源进行筛选分割会导致数据流的多次复制,从而造成不必要的性能浪费。为了解决这个问题,Flink引入了侧输出(Side Output)机制,该机制可以将数据流进行分割,而无需对流进行复制。使用侧输出时,用户可以通过定义输出标签(Output Tag)来标识不同的侧输出流。在处理数据流时,通过适当的操作符和条件,可以将特定类型的数据发送到相应的侧输出流。"}]