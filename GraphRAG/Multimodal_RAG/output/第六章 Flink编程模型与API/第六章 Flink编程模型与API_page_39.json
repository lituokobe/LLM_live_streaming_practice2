[{"bbox": [112, 108, 874, 154], "category": "Text", "text": "关于Flink状态和容错内容参考后续状态和容错章节。"}, {"bbox": [112, 207, 406, 263], "category": "Section-header", "text": "## 6.6.1 FileSink"}, {"bbox": [112, 299, 1576, 447], "category": "Text", "text": "Flink1.12版本之前将数据流实时写入到文件中可以通过StreamFileSink对象来完成，Flink1.12版本之后官方建议使用FileSink对象批或者流数据写出到文件，该对象实现了两阶段提交，可以保证数据以exactly-once语义写出到外部文件。"}, {"bbox": [112, 483, 801, 529], "category": "Text", "text": "将Flink 处理后的数据写入文件目录中,需注意："}, {"bbox": [133, 564, 1587, 1358], "category": "List-item", "text": "* Flink数据写入HDFS中会以 \"yyyy-MM-dd--HH\" 的时间格式给每个目录命名,每个目录也叫一个桶。默认每小时产生一个桶,目录下包含了一些文件,每个 sink 的并发实例都会创建一个属于自己的部分文件,当这些文件太大的时候,sink 会根据设置产生新的部分文件。当一个桶不再活跃时,打开的部分文件会刷盘并且关闭(即:将sink数据写入磁盘,并关闭文件),当再次写入数据会创建新的文件。\n* 生成新的桶目录及桶内文件检查周期是 withBucketCheckInterval(1000) 默认是一分钟。\n* 在桶内生成新的文件规则,以下条件满足一个就会生成新的文件\n  * withInactivityInterval : 桶不活跃的间隔时长,如果一个桶最近一段时间都没有写入,那么这个桶被认为是不活跃的,sink 默认会每分钟检查不活跃的桶、关闭那些超过一分钟没有数据写入的桶。【即:桶内的当下文件如果一分钟没有写入数据就会自动关闭,再次写入数据时,生成新的文件】\n  * withMaxPartSize : 设置文件多大后生成新的文件,默认128M。\n  * withRolloverInterval : 每隔多长时间生成一个新的文件,默认1分钟。\n* 在Flink流数据写出到文件时需要开启checkpoint,否则不能保证数据exactly-once写出语义。Flink checkpoint主要用于状态存储和容错,关于checkpoint更多细节参考状态章节。"}, {"bbox": [112, 1391, 701, 1439], "category": "Text", "text": "**案例：读取socket数据写入到本地文件。**"}, {"bbox": [133, 1474, 529, 1520], "category": "List-item", "text": "* 在项目中导入如下依赖:"}, {"bbox": [128, 1571, 758, 1827], "category": "Text", "text": "```xml\n <!-- DataStream files connector -->\n<dependency>\n  <groupId>org.apache.flink</GROUPID>\n  <artifactId>flink-connector-files</ARTIFACTID>\n  <version>${flink.version}</VERSION>\n</dependency>\n```"}, {"bbox": [133, 1874, 388, 1920], "category": "List-item", "text": "* **Java代码实现**"}, {"bbox": [126, 1972, 1409, 2097], "category": "Text", "text": "```java\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n//开启Checkpoint\nenv.enableCheckpointing(1000);\n```"}]