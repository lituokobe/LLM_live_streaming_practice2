[{"bbox": [109, 123, 1560, 324], "category": "Text", "text": "如果我们想将Flink处理后的数据输出到外部系统或者其他数据库,但是Flink官方没有提供对应的 Sink输出,这时我们可以使用自定义Sink输出,可以实现SinkFunction接口或者继承 RichSinkFunction类并在其中编写处理数据的逻辑即可完成自定义Sink输出,两者区别是后者增加了生命周期的管理功能。通过自定义Sink函数可以将数据发送到任意选择的目标,非常灵活。"}, {"bbox": [109, 357, 1567, 458], "category": "Text", "text": "目前在Flink DataStream API中没有提供HBaseSink,下面以读取Socket数据写入HBase为例来介绍自定义Sink输出,实现数据输出到HBase中。在编写代码之前需要在项目中引入如下Maven依赖。"}, {"bbox": [125, 505, 726, 1060], "category": "Text", "text": "```xml\n <!-- HBase Client 依赖包 -->\n<dependency>\n  <groupId>org.apache.hbase</groupId>\n  <artifactId>hbase-client</ artifactId>\n  <version> ${hbase.version}</version>\n</dependency>\n\n <!-- HBase操作HDFS需要依赖包 -->\n<dependency>\n  <groupId>org.apache.hadoop</groupId>\n  <artifactId>hadoop-auth</ artifactId>\n  <version> ${hadoop.version}</version>\n</dependency>\n```"}, {"bbox": [109, 1103, 529, 1153], "category": "Section-header", "text": "## 1) 在HBase中创建对应的表"}, {"bbox": [123, 1201, 699, 1668], "category": "Text", "text": "```sh\n#启动Zookeeper并启动HDFS\n#启动HBase\n[root@node4 ~]# start-hbase.sh\n\n#进入hbase中创建表 flink-sink-hbase\nhbase:006:0> create 'flink-sink-hbase','cf';\nCreated table flink-sink-hbase\nhbase:007:0> list\n...\nflink-sink-hbase\n...\n```"}, {"bbox": [109, 1718, 294, 1767], "category": "Section-header", "text": "## 2) 编写代码"}, {"bbox": [133, 1801, 388, 1849], "category": "Section-header", "text": "### Java代码实现"}, {"bbox": [123, 1897, 1410, 2069], "category": "Text", "text": "```java\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n/*\n * socket 中输入数据如下:\n * 001,186,187,busy,1000,10\n */\n```"}]